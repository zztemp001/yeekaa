:作者: zztemp找
:邮箱: zztem@gmail.com

goto adsf_

.. contents:: 索引

目录
====
**强调** 第二个字符串
*斜体*
``原文引用``
\*原文*

表格
----
====== ======= ======
输入             输出
-------------- ------
A         B      C
====== ======= ======
False   False   True
True    False   False
====== ======= ======

标题
----
一级标题
========
耳机标题
--------
三级标题
~~~~~~~~

行元素
------
| 第一行
| 第二行

第三行

第四行

缩进
----
| 第一行
| 第二行
|   第三行
|   第四行
|      第五行
|      第六行
| 第七行

超级块元素
==========
外部块
   ok莎拉打开减肥
      阿三哦地方
      阿德发放

.. _adsf:

     阿斯顿飞进啊第三方

    阿斯顿飞进来

.. 注释（一下内容尽在源代码中可见）
  阿斯顿发活动是否
  阿斯顿飞啦算法的

快引用 ::
  asdfiasdfas

  adsfjsad8p909*)()(*
  asdfuoiadf&(*)(

物件
=====
.. _微软: http://www.microsoft.com
.. [叫住1] llllllasdfdsalf

这是 微软_ 。 [叫住1]_

.. contents:: 索引

``
爬虫的两部分，一是下载 Web 页面，有许多问题需要考虑，
如何最大程度地利用本地带宽，如何调度针对不同站点的 Web 请求以减轻对方服务器的负担等。
一个高性能的 Web Crawler 系统里，DNS 查询也会成为急需优化的瓶颈，
另外，还有一些“行规”需要遵循（例如 robots.txt）。
而获取了网页之后的分析过程也是非常复杂的，
Internet 上的东西千奇百怪，各种错误百出的 HTML 页面都有，
要想全部分析清楚几乎是不可能的事；另外，随着 AJAX 的流行，
如何获取由 Javascript 动态生成的内容成了一大难题；
除此之外，Internet 上还有有各种有意或无意出现的 Spider Trap ，
如果盲目的跟踪超链接的话，就会陷入 Trap 中万劫不复了，
例如这个网站，据说是之前 Google 宣称 Internet
上的 Unique URL 数目已经达到了 1 trillion 个，
因此这个人 is proud to announce the second trillion 。``

.. code-block:: python

    def say_hello():
        print 'aldslfjfdsa'

    def asdlfj():
        print 'ok'