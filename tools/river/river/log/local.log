2012-10-18 14:33:03+0800 [scrapy] INFO: Scrapy 0.14.4 started (bot: chrome)
2012-10-18 14:33:04+0800 [scrapy] DEBUG: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2012-10-18 14:33:05+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, CookiesMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats
2012-10-18 14:33:05+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2012-10-18 14:33:05+0800 [scrapy] DEBUG: Enabled item pipelines: 
2012-10-18 14:33:05+0800 [dianping] INFO: Spider opened
2012-10-18 14:33:05+0800 [dianping] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2012-10-18 14:33:05+0800 [scrapy] DEBUG: Telnet console listening on 0.0.0.0:6023
2012-10-18 14:33:05+0800 [scrapy] DEBUG: Web service listening on 0.0.0.0:6080
2012-10-18 14:33:06+0800 [dianping] DEBUG: Crawled (200) <GET http://127.0.0.1/static/page/dianping.htm> (referer: None)
2012-10-18 14:33:06+0800 [dianping] DEBUG: Scraped from <200 http://127.0.0.1/static/page/dianping.htm>
	{}
2012-10-18 14:33:06+0800 [dianping] INFO: Closing spider (finished)
2012-10-18 14:33:06+0800 [dianping] INFO: Dumping spider stats:
	{'downloader/request_bytes': 216,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 142115,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2012, 10, 18, 6, 33, 6, 46000),
	 'item_scraped_count': 1,
	 'scheduler/memory_enqueued': 1,
	 'start_time': datetime.datetime(2012, 10, 18, 6, 33, 5, 984000)}
2012-10-18 14:33:06+0800 [dianping] INFO: Spider closed (finished)
2012-10-18 14:33:06+0800 [scrapy] INFO: Dumping global stats:
	{}
2012-10-18 14:47:45+0800 [scrapy] INFO: Scrapy 0.14.4 started (bot: chrome)
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, RedirectMiddleware, CookiesMiddleware, HttpCompressionMiddleware, ChunkedTransferMiddleware, DownloaderStats
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Enabled item pipelines: 
2012-10-18 14:47:45+0800 [dianping] INFO: Spider opened
2012-10-18 14:47:45+0800 [dianping] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Telnet console listening on 0.0.0.0:6023
2012-10-18 14:47:45+0800 [scrapy] DEBUG: Web service listening on 0.0.0.0:6080
2012-10-18 14:47:45+0800 [dianping] DEBUG: Crawled (200) <GET http://127.0.0.1/static/page/dianping.htm> (referer: None)
2012-10-18 14:47:45+0800 [dianping] ERROR: Spider error processing <GET http://127.0.0.1/static/page/dianping.htm>
	Traceback (most recent call last):
	  File "C:\Program Files\Python27\lib\site-packages\twisted-12.1.0-py2.7-win32.egg\twisted\internet\base.py", line 1178, in mainLoop
	    self.runUntilCurrent()
	  File "C:\Program Files\Python27\lib\site-packages\twisted-12.1.0-py2.7-win32.egg\twisted\internet\base.py", line 800, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "C:\Program Files\Python27\lib\site-packages\twisted-12.1.0-py2.7-win32.egg\twisted\internet\defer.py", line 368, in callback
	    self._startRunCallbacks(result)
	  File "C:\Program Files\Python27\lib\site-packages\twisted-12.1.0-py2.7-win32.egg\twisted\internet\defer.py", line 464, in _startRunCallbacks
	    self._runCallbacks()
	--- <exception caught here> ---
	  File "C:\Program Files\Python27\lib\site-packages\twisted-12.1.0-py2.7-win32.egg\twisted\internet\defer.py", line 551, in _runCallbacks
	    current.result = callback(current.result, *args, **kw)
	  File "D:\GitHub\yeekaa\tools\river\river\spiders\baseinfo.py", line 45, in parse
	    print city.select('text()').extract()[0]
	exceptions.IndexError: list index out of range
	
2012-10-18 14:47:45+0800 [dianping] INFO: Closing spider (finished)
2012-10-18 14:47:45+0800 [dianping] INFO: Dumping spider stats:
	{'downloader/request_bytes': 216,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'downloader/response_bytes': 142115,
	 'downloader/response_count': 1,
	 'downloader/response_status_count/200': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2012, 10, 18, 6, 47, 45, 921000),
	 'scheduler/memory_enqueued': 1,
	 'spider_exceptions/IndexError': 1,
	 'start_time': datetime.datetime(2012, 10, 18, 6, 47, 45, 609000)}
2012-10-18 14:47:45+0800 [dianping] INFO: Spider closed (finished)
2012-10-18 14:47:45+0800 [scrapy] INFO: Dumping global stats:
	{}
